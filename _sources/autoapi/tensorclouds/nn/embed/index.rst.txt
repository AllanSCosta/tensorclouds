tensorclouds.nn.embed
=====================

.. py:module:: tensorclouds.nn.embed


Classes
-------

.. autoapisummary::

   tensorclouds.nn.embed.Embed
   tensorclouds.nn.embed.PairwiseEmbed
   tensorclouds.nn.embed.ApproximateTimeEmbed
   tensorclouds.nn.embed.OnehotTimeEmbed
   tensorclouds.nn.embed.SequenceDistanceEmbed
   tensorclouds.nn.embed.SpatialDistanceEmbed


Module Contents
---------------

.. py:class:: Embed

   Bases: :py:obj:`flax.linen.Module`


   Base class for all neural network modules.

   Layers and models should subclass this class.

   All Flax Modules are Python 3.7
   `dataclasses <https://docs.python.org/3/library/dataclasses.html>`_. Since
   dataclasses take over ``__init__``, you should instead override :meth:`setup`,
   which is automatically called to initialize the module.

   Modules can contain submodules, and in this way can be nested in a tree
   structure. Submodels can be assigned as regular attributes inside the
   :meth:`setup` method.

   You can define arbitrary "forward pass" methods on your Module subclass.
   While no methods are special-cased, ``__call__`` is a popular choice because
   it allows you to use module instances as if they are functions::

     >>> from flax import linen as nn
     >>> from typing import Tuple

     >>> class Module(nn.Module):
     ...   features: Tuple[int, ...] = (16, 4)

     ...   def setup(self):
     ...     self.dense1 = nn.Dense(self.features[0])
     ...     self.dense2 = nn.Dense(self.features[1])

     ...   def __call__(self, x):
     ...     return self.dense2(nn.relu(self.dense1(x)))

   Optionally, for more concise module implementations where submodules
   definitions are co-located with their usage, you can use the
   :meth:`compact` wrapper.


.. py:class:: PairwiseEmbed

   Bases: :py:obj:`flax.linen.Module`


   Base class for all neural network modules.

   Layers and models should subclass this class.

   All Flax Modules are Python 3.7
   `dataclasses <https://docs.python.org/3/library/dataclasses.html>`_. Since
   dataclasses take over ``__init__``, you should instead override :meth:`setup`,
   which is automatically called to initialize the module.

   Modules can contain submodules, and in this way can be nested in a tree
   structure. Submodels can be assigned as regular attributes inside the
   :meth:`setup` method.

   You can define arbitrary "forward pass" methods on your Module subclass.
   While no methods are special-cased, ``__call__`` is a popular choice because
   it allows you to use module instances as if they are functions::

     >>> from flax import linen as nn
     >>> from typing import Tuple

     >>> class Module(nn.Module):
     ...   features: Tuple[int, ...] = (16, 4)

     ...   def setup(self):
     ...     self.dense1 = nn.Dense(self.features[0])
     ...     self.dense2 = nn.Dense(self.features[1])

     ...   def __call__(self, x):
     ...     return self.dense2(nn.relu(self.dense1(x)))

   Optionally, for more concise module implementations where submodules
   definitions are co-located with their usage, you can use the
   :meth:`compact` wrapper.


.. py:class:: ApproximateTimeEmbed

   Bases: :py:obj:`Embed`


   Base class for all neural network modules.

   Layers and models should subclass this class.

   All Flax Modules are Python 3.7
   `dataclasses <https://docs.python.org/3/library/dataclasses.html>`_. Since
   dataclasses take over ``__init__``, you should instead override :meth:`setup`,
   which is automatically called to initialize the module.

   Modules can contain submodules, and in this way can be nested in a tree
   structure. Submodels can be assigned as regular attributes inside the
   :meth:`setup` method.

   You can define arbitrary "forward pass" methods on your Module subclass.
   While no methods are special-cased, ``__call__`` is a popular choice because
   it allows you to use module instances as if they are functions::

     >>> from flax import linen as nn
     >>> from typing import Tuple

     >>> class Module(nn.Module):
     ...   features: Tuple[int, ...] = (16, 4)

     ...   def setup(self):
     ...     self.dense1 = nn.Dense(self.features[0])
     ...     self.dense2 = nn.Dense(self.features[1])

     ...   def __call__(self, x):
     ...     return self.dense2(nn.relu(self.dense1(x)))

   Optionally, for more concise module implementations where submodules
   definitions are co-located with their usage, you can use the
   :meth:`compact` wrapper.


   .. py:attribute:: timesteps
      :type:  int


.. py:class:: OnehotTimeEmbed

   Bases: :py:obj:`Embed`


   Base class for all neural network modules.

   Layers and models should subclass this class.

   All Flax Modules are Python 3.7
   `dataclasses <https://docs.python.org/3/library/dataclasses.html>`_. Since
   dataclasses take over ``__init__``, you should instead override :meth:`setup`,
   which is automatically called to initialize the module.

   Modules can contain submodules, and in this way can be nested in a tree
   structure. Submodels can be assigned as regular attributes inside the
   :meth:`setup` method.

   You can define arbitrary "forward pass" methods on your Module subclass.
   While no methods are special-cased, ``__call__`` is a popular choice because
   it allows you to use module instances as if they are functions::

     >>> from flax import linen as nn
     >>> from typing import Tuple

     >>> class Module(nn.Module):
     ...   features: Tuple[int, ...] = (16, 4)

     ...   def setup(self):
     ...     self.dense1 = nn.Dense(self.features[0])
     ...     self.dense2 = nn.Dense(self.features[1])

     ...   def __call__(self, x):
     ...     return self.dense2(nn.relu(self.dense1(x)))

   Optionally, for more concise module implementations where submodules
   definitions are co-located with their usage, you can use the
   :meth:`compact` wrapper.


   .. py:attribute:: timesteps
      :type:  int
      :value: 1000



   .. py:attribute:: time_range
      :type:  Tuple[int]
      :value: (0.0, 1.0)



.. py:class:: SequenceDistanceEmbed

   Bases: :py:obj:`PairwiseEmbed`


   Base class for all neural network modules.

   Layers and models should subclass this class.

   All Flax Modules are Python 3.7
   `dataclasses <https://docs.python.org/3/library/dataclasses.html>`_. Since
   dataclasses take over ``__init__``, you should instead override :meth:`setup`,
   which is automatically called to initialize the module.

   Modules can contain submodules, and in this way can be nested in a tree
   structure. Submodels can be assigned as regular attributes inside the
   :meth:`setup` method.

   You can define arbitrary "forward pass" methods on your Module subclass.
   While no methods are special-cased, ``__call__`` is a popular choice because
   it allows you to use module instances as if they are functions::

     >>> from flax import linen as nn
     >>> from typing import Tuple

     >>> class Module(nn.Module):
     ...   features: Tuple[int, ...] = (16, 4)

     ...   def setup(self):
     ...     self.dense1 = nn.Dense(self.features[0])
     ...     self.dense2 = nn.Dense(self.features[1])

     ...   def __call__(self, x):
     ...     return self.dense2(nn.relu(self.dense1(x)))

   Optionally, for more concise module implementations where submodules
   definitions are co-located with their usage, you can use the
   :meth:`compact` wrapper.


   .. py:attribute:: k
      :type:  int


   .. py:attribute:: dim
      :type:  int


.. py:class:: SpatialDistanceEmbed

   Bases: :py:obj:`PairwiseEmbed`


   Base class for all neural network modules.

   Layers and models should subclass this class.

   All Flax Modules are Python 3.7
   `dataclasses <https://docs.python.org/3/library/dataclasses.html>`_. Since
   dataclasses take over ``__init__``, you should instead override :meth:`setup`,
   which is automatically called to initialize the module.

   Modules can contain submodules, and in this way can be nested in a tree
   structure. Submodels can be assigned as regular attributes inside the
   :meth:`setup` method.

   You can define arbitrary "forward pass" methods on your Module subclass.
   While no methods are special-cased, ``__call__`` is a popular choice because
   it allows you to use module instances as if they are functions::

     >>> from flax import linen as nn
     >>> from typing import Tuple

     >>> class Module(nn.Module):
     ...   features: Tuple[int, ...] = (16, 4)

     ...   def setup(self):
     ...     self.dense1 = nn.Dense(self.features[0])
     ...     self.dense2 = nn.Dense(self.features[1])

     ...   def __call__(self, x):
     ...     return self.dense2(nn.relu(self.dense1(x)))

   Optionally, for more concise module implementations where submodules
   definitions are co-located with their usage, you can use the
   :meth:`compact` wrapper.


   .. py:attribute:: dim
      :type:  int


   .. py:attribute:: basis
      :type:  str
      :value: 'gaussian'



   .. py:attribute:: cut
      :type:  float
      :value: 24.0



